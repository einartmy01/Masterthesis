\subsection{Car Control}
Remotely operation of cars has been thoroughly researched as it is one of the most common vehicles in the market. Still, remote operating them bring a lot of challenges and demands which makes it a ever continuing research objective.

\subsubsection{Ouden 2022}

The paper \cite{ouden2022} investigates how remote driving performs over commercial 4G and 5G networks. Its purpose is to evaluate whether current mobile networks can support safe remote control of vehicles at low speeds. The authors design a complete remote driving architecture with vehicles, remote stations, fleet management, and a 5G mobile setup. They test the system both in Hardware in the Loop simulations and in real field trials using straight line braking and slalom manoeuvres. The study measures position accuracy, reaction time effects, and communication latency, comparing 4G and 5G performance. Results show that 5G halves network latency compared to 4G and that overall network performance is sufficient for remote driving below 40 km/h, although total reaction delay is still dominated by video processing and human reaction time rather than the network itself.

\subsubsection{Jernberg 2024}

Jernberg \cite{jernberg2024} investigates how latency, driving speed, and task type affect remote operation performance in a controlled simulator environment. The study exposes participants to rural and urban driving scenarios containing several hazards while systematically varying latency between baseline, +100 ms, and +200 ms. The aim is to understand how these factors influence reaction times, safety margins, perceived control, and driving behaviour.

The study measures several quantitative performance indicators such as reaction time from hazard onset to brake input, speed variation across the hazard segment, minimal distance to the hazard object, and post-encroachment time. These measurements are logged automatically in the simulator with fixed measurement windows before and after each hazard event. Hazards and environments are fully balanced so that each participant encounters all combinations of latency, speed, and task. The study also collects subjective ratings between each condition to capture perceived control, workload, and comfort. Comparisons between conditions are performed using mixed-design ANOVAs, allowing the authors to analyse how each factor independently and jointly influences the measurement values.

\subsubsection{Kaknjo 2018}

Kaknjo et al. \cite{kaknjo2018videolatency} present a study on how to measure real-time video latency between a robot and a remote control station. The main purpose is to build a method that reliably captures one-way video delay with higher accuracy than existing tools, especially for applications that require low latency video feedback. The authors design a measurement setup using dedicated NTP servers, synchronized nodes, and software that generates precise visual events. Latency is measured by comparing timestamps from the event generator with the detection time in the received video frames. They test several configurations including web camera scenarios, PPS LED triggering, and network streaming over LAN and the Internet, while separating capture and display delay from pure network transport delay. 

Their method enables accurate measurement of both one-way and total video latency in different streaming conditions, providing insights into how camera settings, encoding, and network type influence delay. They show that latency can vary significantly depending on protocol, encoding, and connection type, and that reliable measurement requires tight time synchronization. 

\subsubsection{Neumeier 2019}

\textit{Teleoperation: The Holy Grail to Solve Problems of Automated Driving? Sure, but Latency Matters} of Neumeier et al. \cite{neumeier2019}, which is a highly cited and used report, investigate how latency affects human performance in teleoperated driving. The purpose of the study is to evaluate how different fixed and varying latency levels influence controllability, workload, and driving behaviour when a human remotely operates a simulated vehicle. The authors implement a static driving simulator with three large displays and inject controlled input and output delays to simulate realistic network conditions. Participants drive several predefined scenarios including following a lane, slalom, parking, and a long track with changing latency while the system continuously logs steering, speed and lane deviation.

Data collection focuses on quantifying behaviour through objective metrics such as Mean Lateral Position, Standard Deviation of Lateral Position, maximum steering angle, speed, and acceleration patterns. Latency conditions are compared using statistical methods to understand how increasing delay changes performance. The study also includes subjective workload measurements and questionnaires. In general, the work shows that higher latency increases workload and negatively impacts control, while smaller delays are easier to compensate for.


\subsubsection{Kang 2018}

Kang et al. \cite{kang2018} explore how remote control can act as a fallback when a self-driving system encounters situations it cannot interpret. The paper outlines typical failure cases, such as unclear road signs, malfunctioning traffic lights, or confusing construction layouts, and argues that a remote human operator can manage these situations when autonomy fails. Supporting the claim that remote operation is necessary for full automation. To investigate feasibility, the authors build a real-time video streaming test and measure how current LTE and WiFi networks affect frame latency. In the report they vary resolution and bitrate across multiple settings while streaming compressed video from a mobile device to a remote server and back. Measurements include two-way frame delay, frame-loss rate, and how latency scales with frame size. The study provides reference values for achievable streaming performance under real conditions and highlights technical challenges that future remote driving systems must account for. 